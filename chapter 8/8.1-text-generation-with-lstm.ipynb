{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T10:44:21.387924Z",
     "start_time": "2019-03-11T10:44:21.356922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncreated on 11 Mar 2019\\n\\n@author: Huan Zheng\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "created on 11 Mar 2019\n",
    "\n",
    "@author: Huan Zheng\n",
    "\"\"\"\n",
    "# 使用LSTM生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成式循环网络简史\n",
    "# 如何生成序列数据\n",
    "# 采样策略的重要性\n",
    "## 对于不同的softmax温度，对概率分布进行重新加权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T10:51:54.317830Z",
     "start_time": "2019-03-11T10:51:54.308830Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reweight_distribution(original_distribution, temperature=0.5):\n",
    "    distribution = np.log(original_distribution) / temperature\n",
    "    distribution = np.exp(distribution)\n",
    "    return distribution / np.sum(distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现字符级的LSTM文本生成\n",
    "## 下载并解析初始文本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T01:25:21.867720Z",
     "start_time": "2019-03-12T01:24:38.652248Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 106496\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file('nietzsche', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将字符序列向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T01:38:05.495397Z",
     "start_time": "2019-03-12T01:38:04.102317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 35479\n",
      "Unique characters: 52\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "maxlen = 60 # 提取60个字符组成的序列\n",
    "step = 3 # 每3个字符采样一个新序列\n",
    "sentences = [] # 保存所提取的序列\n",
    "next_chars = [] # 保存目标（即下一个字符）\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "chars = sorted(list(set(text))) # 语料中唯一字符组成的集合\n",
    "print('Unique characters:', len(chars))\n",
    "char_indices = dict((char, chars.index(char)) for char in chars) # 一个字典，将唯一字符映射为它在列表chars中的索引\n",
    "\n",
    "print('Vectorization...')\n",
    "# one-hot编码\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用于预测下一个字符的单层LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T01:40:30.269677Z",
     "start_time": "2019-03-12T01:40:26.598467Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型编译配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T01:41:32.152217Z",
     "start_time": "2019-03-12T01:41:32.058211Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 给定模型预测、采样下一个字符的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T01:45:45.353699Z",
     "start_time": "2019-03-12T01:45:45.346699Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本生成循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T02:39:48.588201Z",
     "start_time": "2019-03-12T02:20:36.140285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 49s 1ms/step - loss: 1.0940\n",
      "---Generating with seed: \" really ought to free ourselves\n",
      "from the misleading signific\"\n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 49s 1ms/step - loss: 1.0333\n",
      "---Generating with seed: \" anywhere\n",
      "previously; with such a tensely strained bow one c\"\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 49s 1ms/step - loss: 0.9927\n",
      "---Generating with seed: \"\n",
      "herald-calls which summon the bravest to their bravery. boo\"\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 52s 1ms/step - loss: 0.9674\n",
      "---Generating with seed: \"ng be\n",
      "only superficial valuations, special kinds of _niaiser\"\n",
      "epoch 5\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 51s 1ms/step - loss: 0.9408\n",
      "---Generating with seed: \"ds\n",
      "branches off and develops itself in organic processes (na\"\n",
      "epoch 6\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 51s 1ms/step - loss: 0.9223\n",
      "---Generating with seed: \"lly only operate on \"will\"--and not on \"matter\" (not\n",
      "on \"ner\"\n",
      "epoch 7\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 49s 1ms/step - loss: 0.9021\n",
      "---Generating with seed: \"trust--it is possible that the older psychologists had a\n",
      "mer\"\n",
      "epoch 8\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 49s 1ms/step - loss: 0.8866\n",
      "---Generating with seed: \" amounted to\n",
      "the very inversion of truth, and the denial of \"\n",
      "epoch 9\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 52s 1ms/step - loss: 0.8716\n",
      "---Generating with seed: \"injurious, obstructive,\n",
      "blinding, and distorting manner. a p\"\n",
      "epoch 10\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 53s 2ms/step - loss: 0.8541\n",
      "---Generating with seed: \"f\n",
      "desires and passions, that we cannot sink or rise to any o\"\n",
      "epoch 11\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 51s 1ms/step - loss: 0.8433\n",
      "---Generating with seed: \" actor). and the latter is really the malignant reproach tha\"\n",
      "epoch 12\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 54s 2ms/step - loss: 0.8344\n",
      "---Generating with seed: \"tator and actor lurks in him;\n",
      "and if one has hitherto contem\"\n",
      "epoch 13\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 52s 1ms/step - loss: 0.8242\n",
      "---Generating with seed: \"eninsula\n",
      "europe, which would like, by all means, to figure b\"\n",
      "epoch 14\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 48s 1ms/step - loss: 0.8157\n",
      "---Generating with seed: \"so extremely antipodal\n",
      "to my ears and habits of thought, tha\"\n",
      "epoch 15\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 48s 1ms/step - loss: 0.8084\n",
      "---Generating with seed: \" as the sole origin and antecedent history of an action:\n",
      "und\"\n",
      "epoch 16\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 49s 1ms/step - loss: 0.7914\n",
      "---Generating with seed: \"n be common is always of\n",
      "small value. in the end things must\"\n",
      "epoch 17\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 49s 1ms/step - loss: 0.7816\n",
      "---Generating with seed: \"aintenance of a definite\n",
      "mode of life for example, that the \"\n",
      "epoch 18\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 49s 1ms/step - loss: 0.7721\n",
      "---Generating with seed: \"the term \"philosopher\" be not confined to the\n",
      "philosopher wh\"\n",
      "epoch 19\n",
      "Epoch 1/1\n",
      "35479/35479 [==============================] - 49s 1ms/step - loss: 0.7729\n",
      "---Generating with seed: \"itself profoundly and\n",
      "frightfully with this very folly. the \"\n",
      "--- temperature: 0.2\n",
      "itself profoundly and\n",
      "frightfully with this very folly. the cour posiis of all the to later in its ow\n",
      "though the personing as a man one makes to can to the comelition in thinking is thought; and interpretation, the end that is tall to renat of the self-esses to decepation of the world of end supposing that is the begrt. as if a most frequently centrated and spirity in madus, and in the manguse still rangers. for every most that it is to the conditionalness--- temperature: 0.5\n",
      "ll rangers. for every most that it is to the conditionalnessly afterly and a something is though of the \"inted to any one consequently certain,\" with a virtuet of the profound\n",
      "ressience as an explsiol was forch, mushctions of the self-manices. the desire of all scauraty ant with the sign of all the hardist there is nothing is sempt of the subje"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\Anaconda3.5\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct-hims of will to deser is the clas forcestial doiblicts of the mang success, that it is that the very any haltic--- temperature: 1.0\n",
      "cts of the mang success, that it is that the very any halticl was fort artunt of the however and the gover at in effect, without instincts of should beside and and bodulvess suitabition was for a stinting in a worth. ariato de\"pialess in nament call; we have one's skeptofing of histing difficati and arturlfreen\n",
      "and man--thes findless\n",
      "and profound\n",
      "surming in not dued the most see had the manguage,\n",
      "fen the world, without a wable still for a distring man. of --- temperature: 1.2\n",
      "fen the world, without a wable still for a distring man. of \"beyog\" to perhaps briuans of chisition, i may be views tastewwh--as without day the breall ypomes, in all the to ducienness and ressem\n",
      "ence, not\n",
      "on fries and vilues that nothing wien pencaue\n",
      "to reard alon thinking relare he would so ngiaal part! and no enversares a discology\n",
      "as it\n",
      "is\n",
      "necriation of of its oped of the is sacroy perhaps suien, readilly\n",
      "apparity have ougns, so prour which can 'thes f"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    print('epoch', epoch)\n",
    "    model.fit(x, y, batch_size=256, epochs=1) # 将模型在数据上拟合一次\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1) # 随机选取一个文本种子\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('---Generating with seed: \"' + generated_text +'\"')\n",
    "\n",
    "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print('--- temperature:', temperature)\n",
    "    sys.stdout.write(generated_text)\n",
    "    \n",
    "    for i in range(400):\n",
    "        # 对目前生成的字符进行one-hot编码\n",
    "        sampled = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(generated_text):\n",
    "            sampled[0, t, char_indices[char]] = 1\n",
    "\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_idnex = sample(preds, temperature)\n",
    "        next_char = chars[next_idnex]\n",
    "\n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "\n",
    "        sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
